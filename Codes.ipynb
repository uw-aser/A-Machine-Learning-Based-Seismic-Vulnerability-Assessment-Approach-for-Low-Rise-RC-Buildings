{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Title:** A Machine Learning-Based Seismic Vulnerability Assessment Approach for Low-Rise RC Buildings \n",
        "\n",
        "#### **Developed by:**\n",
        "#### Niloofar Elyasi, Eugene Kim & Chul Min Yeum"
      ],
      "metadata": {
        "id": "lnAMBAcoMXYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import packages**"
      ],
      "metadata": {
        "id": "cjKNinvyNLnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "import statistics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from matplotlib.offsetbox import AnchoredText"
      ],
      "metadata": {
        "id": "x2nPjfZxN_kk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Read the data**"
      ],
      "metadata": {
        "id": "TK0z8YjeOVdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/Six Earthquake Datasets.xlsx')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Quppu2kXOjs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CI-WI Scatter plots of Datasetes (Figure 5)**"
      ],
      "metadata": {
        "id": "2oX1ZfdnUHSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CI_WI_plot(eq = \"1999_Duzce\", frac = 1, ax=None):\n",
        "\n",
        "  df = data[data.EQID == eq]\n",
        "\n",
        "  df.loc[df.SDMG == 'N', \"SDMG\"] = 'Light'\n",
        "  df.loc[df.SDMG == 'L', \"SDMG\"] = 'Light'\n",
        "  df.loc[df.SDMG == 'M', \"SDMG\"] = 'Moderate'\n",
        "  df.loc[df.SDMG == 'S', \"SDMG\"] = 'Severe'\n",
        "\n",
        "  df1 = df[df.SDMG=='Light']\n",
        "  df2 = df[df.SDMG=='Moderate']\n",
        "  df3 = df[df.SDMG=='Severe']\n",
        "\n",
        "  sns.scatterplot(ax=ax, x=\"CIND\", y=\"WIND\",  marker  = \"^\", label = 'Light' ,data=df1, s=180, alpha=0.5)\n",
        "  sns.scatterplot(ax=ax, x=\"CIND\", y=\"WIND\",  marker = \"s\", label = 'Moderate',data=df2, s=250, alpha=0.9)\n",
        "  sns.scatterplot(ax=ax, x=\"CIND\", y=\"WIND\",  marker = \"o\", label = 'Severe',data=df3, s=180, alpha=0.4)\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(20, 20))\n",
        "CI_WI_plot(\"1999_Duzce\", 1, ax=axes[0, 0])\n",
        "axes[0, 0].set_title(\"1999 Duzce\", fontsize=15, fontweight='bold')\n",
        "axes[0, 0].set_xlim(-0.02, 0.9)\n",
        "axes[0, 0].set_ylim(-0.02, 0.35)  \n",
        "\n",
        "CI_WI_plot(\"2003_Bingol\", 1, ax=axes[0, 1])\n",
        "axes[0, 1].set_title(\"2003 Bingol\", fontsize=15, fontweight='bold')\n",
        "axes[0, 1].set_xlim(-0.02, 0.45)\n",
        "axes[0, 1].set_ylim(-0.02, 0.55)  \n",
        "\n",
        "CI_WI_plot(\"2015_Nepal\", 1, ax=axes[1, 0])\n",
        "axes[1, 0].set_title(\"2015 Nepal\", fontsize=15, fontweight='bold')\n",
        "axes[1, 0].set_xlim(-0.02, 0.8)\n",
        "axes[1, 0].set_ylim(-0.02, 0.2)  \n",
        "\n",
        "CI_WI_plot(\"2016_Taiwan\", 1, ax=axes[1, 1])\n",
        "axes[1, 1].set_title(\"2016 Taiwan\", fontsize=15, fontweight='bold')\n",
        "axes[1, 1].set_xlim(-0.02, 1)\n",
        "axes[1, 1].set_ylim(-0.02, 0.8)  \n",
        "\n",
        "CI_WI_plot(\"2016_Ecuador\", 1, ax=axes[2, 0])\n",
        "axes[2, 0].set_title(\"2016 Ecuador\", fontsize=15, fontweight='bold')\n",
        "axes[2, 0].set_xlim(-0.02, 0.85)\n",
        "axes[2, 0].set_ylim(-0.02, 0.25)  \n",
        "\n",
        "CI_WI_plot(\"2017_Pohang\", 1, ax=axes[2, 1])\n",
        "axes[2, 1].set_title(\"2017 Pohang\", fontsize=15, fontweight='bold')\n",
        "axes[2, 1].set_xlim(-0.02, 0.6)\n",
        "axes[2, 1].set_ylim(-0.02, 0.5)  \n",
        "\n",
        "for ax in axes.flat:\n",
        "  ax.set_xlabel(\"CI\", fontsize=15, fontweight='bold')\n",
        "  ax.set_ylabel(\"WI\", fontsize=15, fontweight='bold')\n",
        "  ax.legend(fontsize=13.0)\n",
        "\n",
        "  for tick in ax.xaxis.get_majorticklabels():  \n",
        "    tick.set_fontsize(13)\n",
        "    tick.set_fontweight('bold')  \n",
        "\n",
        "  for tick in ax.yaxis.get_majorticklabels():  \n",
        "    tick.set_fontsize(12)\n",
        "    tick.set_fontweight('bold')  "
      ],
      "metadata": {
        "id": "Fq2E1QwhUH51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PI-based seismic damage prediction accuracies (Table 2)**"
      ],
      "metadata": {
        "id": "OPNNY6mwOoth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PI_based(eq = \"1999_Duzce\", data=data):\n",
        "\n",
        "  print (\"### \" + eq + \" ###\")\n",
        "\n",
        "  sub_data= data.loc[data[\"EQID\"] == eq]\n",
        "\n",
        "  # No damage is merged with light damage & moderate damage is merged with severe damage\n",
        "  sub_data.loc[sub_data.SDMG == 'N', \"SDMG\"] = 'L'\n",
        "  sub_data.loc[sub_data.SDMG == 'M', \"SDMG\"] = 'S'\n",
        "\n",
        "  # PI is the only input feature and damage state is the output label\n",
        "  input_features = [\"PIND\"]\n",
        "  X = sub_data[input_features]\n",
        "  Y = sub_data[\"SDMG\"]\n",
        "\n",
        "  PI_logreg = LogisticRegression(multi_class='multinomial', class_weight='balanced')\n",
        "\n",
        "  # 5-Fold Cross Validation\n",
        "  kf = KFold(n_splits=5, shuffle=True)\n",
        "  accuracy_f1 = []\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    x_train, x_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
        "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "    PI_logreg.fit(x_train, y_train)\n",
        "    accuracy_f1.append(f1_score(y_test, PI_logreg.predict(x_test), average='weighted'))\n",
        "\n",
        "  print(\"KFold Cross Validation: \")\n",
        "  print (\"f1_score: \") \n",
        "  print (accuracy_f1)\n",
        "  print (\"Mean Accuracy: \") \n",
        "  print(statistics.mean(accuracy_f1))\n",
        "  print (\"### END ###\")\n",
        " \n",
        "PI_based(\"1999_Duzce\")\n",
        "PI_based(\"2003_Bingol\")\n",
        "PI_based(\"2015_Nepal\")\n",
        "PI_based(\"2016_Taiwan\")\n",
        "PI_based(\"2016_Ecuador\")\n",
        "PI_based(\"2017_Pohang\")"
      ],
      "metadata": {
        "id": "iP_IDz8cO26i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CI-WI scatter plots with classification boundaries defined by logistic regression (Figure 7)**"
      ],
      "metadata": {
        "id": "hhWKljgPSoNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def db_plot (eq = \"1999_Duzce\", frac = 1, ax=None):\n",
        "  df = data\n",
        "  sub_data = df[df.EQID == eq]\n",
        "  \n",
        "  # No damage is merged with light damage & moderate damage is merged with severe damage\n",
        "  sub_data.loc[sub_data.SDMG == 'N', \"SDMG\"] = 'L'\n",
        "  sub_data.loc[sub_data.SDMG == 'M', \"SDMG\"] = 'S'\n",
        "\n",
        "  sub_data.loc[sub_data['SDMG'] != 'S', 'SDMG'] = 'Non-Severe' \n",
        "  sub_data.loc[sub_data['SDMG'] == 'S', 'SDMG'] = 'Severe'\n",
        "\n",
        "  df1 = sub_data[sub_data.SDMG=='Non-Severe']\n",
        "  df2 = sub_data[sub_data.SDMG=='Severe']\n",
        "\n",
        "  # CI & WI are the input features and damage state is the output label\n",
        "  input_features = [\"CIND\", \"WIND\"]\n",
        "  X = sub_data[input_features]\n",
        "  Y = sub_data[\"SDMG\"]\n",
        "\n",
        "  CI_WI_logreg = LogisticRegression(multi_class='multinomial', class_weight='balanced')\n",
        "\n",
        "  # Accuracy\n",
        "  kf = KFold(n_splits=5, shuffle=True)\n",
        "  accuracy_f1 = []\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    x_train, x_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
        "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "    CI_WI_logreg.fit(x_train, y_train)\n",
        "    accuracy_f1.append(f1_score(y_test, CI_WI_logreg.predict(x_test), average='weighted'))\n",
        "\n",
        "  Accuracy = statistics.mean(accuracy_f1)\n",
        "  Acc = \"Accuracy = %0.2f\"  % Accuracy\n",
        "\n",
        "  # Deining Decision Boundary\n",
        "  b = CI_WI_logreg.intercept_[0]\n",
        "  w1, w2 = CI_WI_logreg.coef_.T\n",
        "\n",
        "  c = -b/w2\n",
        "  m = -w1/w2 \n",
        "\n",
        "  xd = np.array([-0.05, 1])\n",
        "  yd = m * xd + c\n",
        "\n",
        "  if ax is None:\n",
        "        ax = plt.gca()\n",
        "\n",
        "  sns.scatterplot(ax=ax, x=\"CIND\", y=\"WIND\",  marker  = \"o\", label = 'Non-Severe' , data=df1, s=250, alpha=0.9)\n",
        "  sns.scatterplot(ax=ax, x=\"CIND\", y=\"WIND\",  marker = \"s\", label = 'Severe', data=df2, s=250, alpha=0.5)\n",
        "\n",
        "  ax.plot(xd, yd, 'r', lw = 2.5,  ls='--')\n",
        "  ymin, ymax = -0.02, 1\n",
        "  ax.fill_between(xd, yd, ymin, color='tab:orange', alpha = 0.1)\n",
        "  ax.fill_between(xd, yd, ymax, color='tab:blue', alpha = 0.1) \n",
        "\n",
        "  props = dict(boxstyle='square', facecolor='white', alpha=0.5)\n",
        "  ax.text(0.76, 0.8, Acc, transform=ax.transAxes, fontsize=14, fontweight='bold',\n",
        "        verticalalignment='top', bbox=props)\n",
        "\n",
        "# Plotting\n",
        "fig, axes = plt.subplots(3, 2, figsize=(20, 20))\n",
        "db_plot(\"1999_Duzce\", frac = 1, ax=axes[0, 0])\n",
        "axes[0, 0].set_title(\"1999 Duzce\", fontsize=15, fontweight='bold')\n",
        "axes[0, 0].set_xlim(-0.02, 0.9)\n",
        "axes[0, 0].set_ylim(-0.02, 0.35) \n",
        "\n",
        "db_plot(\"2003_Bingol\", frac = 1, ax=axes[0, 1])\n",
        "axes[0, 1].set_title(\"2003 Bingol\", fontsize=15, fontweight='bold')\n",
        "axes[0, 1].set_xlim(-0.02, 0.45)\n",
        "axes[0, 1].set_ylim(-0.02, 0.55)  \n",
        "\n",
        "db_plot(\"2015_Nepal\", frac = 1, ax=axes[1, 0])\n",
        "axes[1, 0].set_title(\"2015 Nepal\", fontsize=15, fontweight='bold')\n",
        "axes[1, 0].set_xlim(-0.02, 0.8)\n",
        "axes[1, 0].set_ylim(-0.02, 0.2)  \n",
        "\n",
        "db_plot(\"2016_Taiwan\", frac = 1, ax=axes[1, 1])\n",
        "axes[1, 1].set_title(\"2016 Taiwan\", fontsize=15, fontweight='bold')\n",
        "axes[1, 1].set_xlim(-0.02, 1)\n",
        "axes[1, 1].set_ylim(-0.02, 0.8)  \n",
        "\n",
        "db_plot(\"2016_Ecuador\", frac = 1, ax=axes[2, 0])\n",
        "axes[2, 0].set_title(\"2016 Ecuador\", fontsize=15, fontweight='bold')\n",
        "axes[2, 0].set_xlim(-0.02, 0.85)\n",
        "axes[2, 0].set_ylim(-0.02, 0.25)  \n",
        "\n",
        "db_plot(\"2017_Pohang\", frac = 1, ax=axes[2, 1])\n",
        "axes[2, 1].set_title(\"2017 Pohang\", fontsize=15, fontweight='bold')\n",
        "axes[2, 1].set_xlim(-0.02, 0.6)\n",
        "axes[2, 1].set_ylim(-0.02, 0.5) \n",
        " \n",
        "\n",
        "for ax in axes.flat:\n",
        "  ax.set_xlabel(\"CI\", fontsize=15, fontweight='bold')\n",
        "  ax.set_ylabel(\"WI\", fontsize=15, fontweight='bold')\n",
        "  ax.legend(fontsize=13.0)\n",
        "\n",
        "  for tick in ax.xaxis.get_majorticklabels():  \n",
        "    tick.set_fontsize(13)\n",
        "    tick.set_fontweight('bold')  \n",
        "\n",
        "  for tick in ax.yaxis.get_majorticklabels():  \n",
        "    tick.set_fontsize(12)\n",
        "    tick.set_fontweight('bold')\n",
        "\n",
        "axes[2, 1].legend(fontsize=13.0, loc=\"upper left\")\n",
        "fig.tight_layout(pad=5.0)"
      ],
      "metadata": {
        "id": "_q226c3YSofv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Region-specific logistic regression model accuracies (Table 3)**"
      ],
      "metadata": {
        "id": "HcGPvcUFPHVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rs_LR(eq = \"1999_Duzce\", data=data):\n",
        "\n",
        "  print (\"### \" + eq + \" ###\")\n",
        "\n",
        "  sub_data = data.loc[data[\"EQID\"] == eq]\n",
        "\n",
        "  # No damage is merged with light damage & moderate damage is merged with severe damage\n",
        "  sub_data.loc[sub_data.SDMG == 'N', \"SDMG\"] = 'L'\n",
        "  sub_data.loc[sub_data.SDMG == 'M', \"SDMG\"] = 'S'\n",
        "\n",
        "  # The seven PI parameters are the input features and damage state is the output label\n",
        "  input_features = np.array ([\"NUMS\", \"FLOA\", \"COLA\", \"MWNS\", \"MWEW\", \"CWNS\", \"CWEW\"])\n",
        "  X = sub_data[input_features]\n",
        "  Y = sub_data[\"SDMG\"]\n",
        "\n",
        "  rs_logreg = LogisticRegression(multi_class='multinomial', class_weight='balanced')\n",
        "\n",
        "  # 5-Fold Cross Validation\n",
        "  kf = KFold(n_splits=5, shuffle=True)\n",
        "  accuracy_f1 = []\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    x_train, x_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
        "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "    rs_logreg.fit(x_train, y_train)\n",
        "    accuracy_f1.append(f1_score(y_test, rs_logreg.predict(x_test), average='weighted'))\n",
        "\n",
        "  print(\"KFold Cross Validation: \")\n",
        "  print (\"f1_score: \") \n",
        "  print (accuracy_f1)\n",
        "  print (\"Mean Accuracy: \") \n",
        "  print(statistics.mean(accuracy_f1))\n",
        "  print (\"### END ###\")\n",
        "\n",
        "rs_LR(\"1999_Duzce\")\n",
        "rs_LR(\"2003_Bingol\")\n",
        "rs_LR(\"2015_Nepal\")\n",
        "rs_LR(\"2016_Taiwan\")\n",
        "rs_LR(\"2016_Ecuador\")\n",
        "rs_LR(\"2017_Pohang\")"
      ],
      "metadata": {
        "id": "mPb9LKSaPjNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Region-specific RF model accuracies (Table 4)**"
      ],
      "metadata": {
        "id": "dRdcYGy-QDsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rs_RF(eq = \"1999_Duzce\", data=data):\n",
        "\n",
        "  print (\"### \" + eq + \" ###\")\n",
        "\n",
        "  sub_data = data.loc[data[\"EQID\"] == eq]\n",
        "\n",
        "  # No damage is merged with light damage & moderate damage is merged with severe damage\n",
        "  sub_data.loc[sub_data.SDMG == 'N', \"SDMG\"] = 'L'\n",
        "  sub_data.loc[sub_data.SDMG == 'M', \"SDMG\"] = 'S'\n",
        "\n",
        "\n",
        "  input_features = np.array ([\"NUMS\", \"FLOA\", \"COLA\", \"MWNS\", \"MWEW\", \"CWNS\", \"CWEW\"])\n",
        "  X = sub_data[input_features]\n",
        "  Y = sub_data[\"SDMG\"]\n",
        "\n",
        "  rs_RandomForest = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=123)\n",
        "\n",
        "  # 5-Fold Cross Validation\n",
        "  kf = KFold(n_splits=5, shuffle=True)\n",
        "  accuracy_f1 = []\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    x_train, x_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
        "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "    rs_RandomForest.fit(x_train, y_train)\n",
        "    accuracy_f1.append(f1_score(y_test, rs_RandomForest.predict(x_test), average='weighted'))\n",
        "\n",
        "  print(\"KFold Cross Validation: \")\n",
        "  print (\"f1_score: \") \n",
        "  print (accuracy_f1)\n",
        "  print (\"Mean Accuracy: \") \n",
        "  print(statistics.mean(accuracy_f1))\n",
        "  print (\"### END ###\")\n",
        "\n",
        "rs_RF(\"1999_Duzce\")\n",
        "rs_RF(\"2003_Bingol\")\n",
        "rs_RF(\"2015_Nepal\")\n",
        "rs_RF(\"2016_Taiwan\")\n",
        "rs_RF(\"2016_Ecuador\")\n",
        "rs_RF(\"2017_Pohang\")"
      ],
      "metadata": {
        "id": "jBxccmUxQEFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model accuracies after adding new input features to the seven PI inputs (Table 5)**"
      ],
      "metadata": {
        "id": "dueBK0BcQeyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model accuracy for the six different scenarios\n",
        "def Scenario(eq_test = \"1999_Duzce\", data=data):\n",
        "\n",
        "  print (\"### \" + eq_test + \" ###\")\n",
        "\n",
        "  df = data\n",
        "\n",
        "  # No damage is merged with light damage & moderate damage is merged with severe damage\n",
        "  df.loc[df.SDMG == 'N', \"SDMG\"] = 'L'\n",
        "  df.loc[df.SDMG == 'M', \"SDMG\"] = 'S'\n",
        "\n",
        "  data_train = df[df.EQID != eq_test]\n",
        "  data_test = df[df.EQID == eq_test]\n",
        "\n",
        "  # The PI seven input features + new input features including \"MMI\", \"PGA\", \"PGV\"\n",
        "  input_features = [\"NUMS\", \"FLOA\", \"COLA\", \"MWNS\", \"MWEW\", \"CWNS\", \"CWEW\", \"MMI\"]\n",
        "\n",
        "  # Assign input features and output labels (train)\n",
        "  x_train = data_train[input_features]\n",
        "  y_train= data_train[['SDMG']]\n",
        "\n",
        "  # Assign input features and output labels (test)\n",
        "  x_test = data_test[input_features]\n",
        "  y_test= data_test[['SDMG']]\n",
        "\n",
        "  # Random Forest Classifier \n",
        "  classifier = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=123)\n",
        "  classifier.fit(x_train, y_train)\n",
        "\n",
        "  accuracy_f1 = f1_score(y_test, classifier.predict(x_test), average='weighted')\n",
        "  print (\"f1_score: \") \n",
        "  print (accuracy_f1)\n",
        "  print (\"### END ###\")\n",
        "\n",
        "Scenario(\"1999_Duzce\")\n",
        "Scenario(\"2003_Bingol\")\n",
        "Scenario(\"2015_Nepal\")\n",
        "Scenario(\"2016_Taiwan\")\n",
        "Scenario(\"2016_Ecuador\")\n",
        "Scenario(\"2017_Pohang\")"
      ],
      "metadata": {
        "id": "othOBaR-QfH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Accuracy of Proposed RVS model trained on a mixed dataset with MMI and PGA input (Table 6)** "
      ],
      "metadata": {
        "id": "gRdhOJ2MRKQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data\n",
        "\n",
        "# Mix all the six datasets\n",
        "df = pd.concat([df[df.EQID == \"2016_Ecuador\"], df[df.EQID == \"2015_Nepal\"], df[df.EQID == \"2016_Taiwan\"], df[df.EQID == \"2003_Bingol\"], df[df.EQID == \"2017_Pohang\"], df[df.EQID == \"1999_Duzce\"]])\n",
        "\n",
        "# No damage is merged with light damage & moderate damage is merged with severe damage\n",
        "df.loc[df.SDMG == 'N', \"SDMG\"] = 'L'\n",
        "df.loc[df.SDMG == 'M', \"SDMG\"] = 'S'\n",
        "\n",
        "# The PI seven input features + \"PGA\" and \"MMI\"\n",
        "input_features = [\"NUMS\", \"FLOA\", \"COLA\", \"MWNS\", \"MWEW\", \"CWNS\", \"CWEW\", \"PGA\", \"MMI\"]\n",
        "\n",
        "# Assign input features and outputlabels\n",
        "X = df[input_features]\n",
        "Y = df['SDMG']\n",
        "\n",
        "# Random Forest Classifier \n",
        "classifier = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=123)\n",
        "\n",
        "# KFold Cross Validation\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "accuracy_f1 = []\n",
        "for train_index, test_index in kf.split(X):\n",
        "  x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "  classifier.fit(x_train, y_train)\n",
        "  accuracy_f1.append(f1_score(y_test, classifier.predict(x_test), average='weighted'))\n",
        "\n",
        "print(\"KFold Cross Validation: \")\n",
        "print (\"f1_score: \") \n",
        "print (accuracy_f1)\n",
        "print (\"Mean Accuracy: \") \n",
        "print(statistics.mean(accuracy_f1))"
      ],
      "metadata": {
        "id": "6NLTGQJzRKiJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}